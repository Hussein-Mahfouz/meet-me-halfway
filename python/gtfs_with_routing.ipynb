{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import heapq\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import os\n",
    "from collections import defaultdict, namedtuple\n",
    "\n",
    "import logging\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Create a handler to display logs in Jupyter notebook's output cell\n",
    "handler = logging.StreamHandler()\n",
    "handler.setLevel(logging.DEBUG)\n",
    "\n",
    "# Format the logs\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract gtfs from zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_gtfs_zip(zip_path, extract_to='gtfs_feed'):\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "\n",
    "# Extract the GTFS feed\n",
    "zip_path = '../data/study_area_gtfs_bus.zip'\n",
    "extract_to = 'gtfs_feed'\n",
    "extract_gtfs_zip(zip_path, extract_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parse gtfs feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "Edge = namedtuple('Edge', ['to', 'weight', 'start_time', 'end_time', 'route'])\n",
    "\n",
    "def parse_gtfs(extract_to, crs='EPSG:3857'):\n",
    "    stops = {}\n",
    "    routes = {}\n",
    "    trips = {}\n",
    "    stop_times = defaultdict(list)\n",
    "\n",
    "    stops_df = pd.read_csv(os.path.join(extract_to, \"stops.txt\"))\n",
    "    stops_gdf = gpd.GeoDataFrame(stops_df, geometry=gpd.points_from_xy(stops_df.stop_lon, stops_df.stop_lat))\n",
    "    stops_gdf.set_crs('EPSG:4326', inplace=True)\n",
    "    stops_gdf = stops_gdf.to_crs(crs)\n",
    "    for index, row in stops_gdf.iterrows():\n",
    "        row_dict = row.to_dict()\n",
    "        row_dict['stop_lon'], row_dict['stop_lat'] = row.geometry.x, row.geometry.y\n",
    "        stops[row['stop_id']] = row_dict\n",
    "\n",
    "    with open(os.path.join(extract_to, \"routes.txt\"), mode='r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            routes[row['route_id']] = row\n",
    "\n",
    "    with open(os.path.join(extract_to, \"trips.txt\"), mode='r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            trips[row['trip_id']] = row\n",
    "\n",
    "    with open(os.path.join(extract_to, \"stop_times.txt\"), mode='r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            stop_times[row['trip_id']].append(row)\n",
    "\n",
    "    return stops, routes, trips, stop_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply\n",
    "stops, routes, trips, stop_times = parse_gtfs(extract_to, crs='EPSG:3857')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate transfer graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(stops.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "stops_list = list(stops.values())\n",
    "\n",
    "stops_location = []\n",
    "for stop in stops_list:\n",
    "    if isinstance(stop, dict) and 'stop_lat' in stop and 'stop_lon' in stop:\n",
    "        stops_location.append((float(stop['stop_lat']), float(stop['stop_lon'])))\n",
    "\n",
    "stops_location\n",
    "\n",
    "if not stops_location:\n",
    "    raise ValueError(\"No valid stops found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btree = KDTree(stops_location)\n",
    "\n",
    "# check values in KDTRree\n",
    "btree.query([stops_location[0]], k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, distances = btree.query_radius(stops_location, r= 300, return_distance=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not stops_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transfers(stops, max_distance_meters, walk_speed_kmph):\n",
    "    if walk_speed_kmph == 0:\n",
    "        raise ValueError(\"walk_speed_kmph cannot be zero\")\n",
    "\n",
    "    transfers = defaultdict(list)\n",
    "    stops_list = list(stops.values())\n",
    "    stops_location = []\n",
    "    for stop in stops_list:\n",
    "        if isinstance(stop, dict) and 'stop_lat' in stop and 'stop_lon' in stop:\n",
    "            stops_location.append((float(stop['stop_lat']), float(stop['stop_lon'])))\n",
    "\n",
    "\n",
    "    if not stops_location:\n",
    "        raise ValueError(\"No valid stops found\")\n",
    "\n",
    "\n",
    "    btree = KDTree(stops_location)\n",
    "\n",
    "    crow_flies_distance_factor = 1.5\n",
    "    indices, distances = btree.query_radius(stops_location, r=max_distance_meters, return_distance=True)\n",
    "\n",
    "    for from_idx, (to_indices, ds) in enumerate(zip(indices, distances)):\n",
    "        for to_idx, d in zip(to_indices, ds):\n",
    "            if from_idx != to_idx:\n",
    "                walk_dis = d * crow_flies_distance_factor\n",
    "                walk_h = walk_dis / 1000 / walk_speed_kmph\n",
    "                walk_sec = walk_h * 60 * 60\n",
    "\n",
    "                transfers[stops_list[from_idx]['stop_id']].append({\n",
    "                    'from_stop_id': stops_list[from_idx]['stop_id'],\n",
    "                    'to_stop_id': stops_list[to_idx]['stop_id'],\n",
    "                    'min_transfer_time': walk_sec\n",
    "                })\n",
    "\n",
    "    return transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate transfers\n",
    "transfers = generate_transfers(stops, max_distance_meters= 1000, walk_speed_kmph= 5)\n",
    "transfers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Graph:\n",
    "    def __init__(self):\n",
    "        self.adj_list = defaultdict(list)\n",
    "\n",
    "    def add_edge(self, from_node, to_node, weight, start_time, end_time, route):\n",
    "        self.adj_list[from_node].append(Edge(to_node, weight, start_time, end_time, route))\n",
    "\n",
    "    def get_nodes(self):\n",
    "        return list(self.adj_list.keys())\n",
    "\n",
    "    def get_edges(self):\n",
    "        edges = []\n",
    "        for from_node, edges_list in self.adj_list.items():\n",
    "            for edge in edges_list:\n",
    "                edges.append((from_node, edge.to, edge.weight, edge.start_time, edge.end_time, edge.route))\n",
    "        return edges\n",
    "\n",
    "def build_graph_from_gtfs(stops, routes, trips, stop_times, transfers):\n",
    "    graph = Graph()\n",
    "    \n",
    "    # Add edges from stop_times\n",
    "    for trip_id, times in stop_times.items():\n",
    "        times.sort(key=lambda x: x['stop_sequence'])  # Ensure stop_times are sorted by stop_sequence\n",
    "        for i in range(len(times) - 1):\n",
    "            from_stop = times[i]['stop_id']\n",
    "            to_stop = times[i + 1]['stop_id']\n",
    "            h, m, s = map(int, times[i]['arrival_time'].split(':'))\n",
    "            start_time = h * 3600 + m * 60 + s\n",
    "            h, m, s = map(int, times[i + 1]['departure_time'].split(':'))\n",
    "            end_time = h * 3600 + m * 60 + s\n",
    "            weight = end_time - start_time\n",
    "            route_id = trips[trip_id]['route_id']\n",
    "            graph.add_edge(from_stop, to_stop, weight, start_time, end_time, route_id)\n",
    "    \n",
    "    # Add transfer edges\n",
    "    for from_stop, trans in transfers.items():\n",
    "        for transfer in trans:\n",
    "            to_stop = transfer['to_stop_id']\n",
    "            min_transfer_time = int(transfer['min_transfer_time'])\n",
    "            graph.add_edge(from_stop, to_stop, weight=min_transfer_time, start_time=0, end_time=float('inf'), route='transfer')\n",
    "\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph from GTFS data\n",
    "graph = build_graph_from_gtfs(stops, routes, trips, stop_times, transfers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = graph.get_nodes()\n",
    "for node in nodes:\n",
    "    print(f\"Node: {node}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = graph.get_edges()\n",
    "for edge in edges:\n",
    "    print(f\"Edge: {edge}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modified djikstra algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dijkstra_with_transfers(graph, start, start_time, max_transfers=3):\n",
    "\n",
    "    # Check if the start node is in the graph\n",
    "    if start not in graph.adj_list:\n",
    "        print(\"Invalid start node. Valid nodes are:\")\n",
    "        for node in graph.adj_list:\n",
    "            print(node)\n",
    "        return None\n",
    "    # Initialize distances, routes, and priority queue\n",
    "    distances = {node: float('inf') for node in graph.adj_list}\n",
    "    distances[start] = 0\n",
    "    priority_queue = [(start_time, start, set(), 0)]  # (time, node, routes, transfers)\n",
    "    shortest_path_tree = {}\n",
    "    routes_used = {node: set() for node in graph.adj_list}\n",
    "    transfers = {node: float('inf') for node in graph.adj_list}\n",
    "    transfers[start] = 0\n",
    "\n",
    "    while priority_queue:\n",
    "        current_time, current_node, current_routes, current_transfers = heapq.heappop(priority_queue)\n",
    "\n",
    "        # If the popped node has a time greater than the currently known shortest time, skip it\n",
    "        if current_time > distances[current_node]:\n",
    "            continue\n",
    "\n",
    "        # Examine and relax edges with time windows and route tracking\n",
    "        for edge in graph.adj_list[current_node]:\n",
    "            if current_time <= edge.end_time:\n",
    "                # Calculate the wait time if necessary\n",
    "                wait_time = max(0, edge.start_time - current_time)\n",
    "                arrival_time = current_time + wait_time + edge.weight\n",
    "\n",
    "                # Calculate the number of transfers\n",
    "                new_transfers = current_transfers\n",
    "                if edge.route not in current_routes:\n",
    "                    new_transfers += 1\n",
    "\n",
    "                # Check if the number of transfers exceeds the maximum allowed\n",
    "                if new_transfers > max_transfers:\n",
    "                    continue\n",
    "\n",
    "                # If this path is shorter or uses fewer transfers, update the time, routes, and transfers\n",
    "                if arrival_time < distances[edge.to] or (arrival_time == distances[edge.to] and new_transfers < transfers[edge.to]):\n",
    "                    distances[edge.to] = arrival_time\n",
    "                    routes_used[edge.to] = current_routes | {edge.route}\n",
    "                    transfers[edge.to] = new_transfers\n",
    "                    heapq.heappush(priority_queue, (arrival_time, edge.to, current_routes | {edge.route}, new_transfers))\n",
    "                    shortest_path_tree[edge.to] = (current_node, edge.route)\n",
    "\n",
    "    return distances, shortest_path_tree, routes_used, transfers\n",
    "\n",
    "def print_shortest_path_tree(shortest_path_tree, routes_used, start):\n",
    "    print(\"Shortest Path Tree:\")\n",
    "    for node, (parent, _) in shortest_path_tree.items():\n",
    "        path = [node]\n",
    "        while parent != start:\n",
    "            path.append(parent)\n",
    "            parent, _ = shortest_path_tree[parent]\n",
    "        path.append(start)\n",
    "        path.reverse()\n",
    "        print(f\"Destination Node: {node}, Path: {' -> '.join(path)}, Routes: {', '.join(routes_used[node])}\")\n",
    "\n",
    "\n",
    "# Create a graph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dijkstra_with_transfers(graph, start, start_time, max_transfers=3):\n",
    "    logging.info(f\"Running Dijkstra's algorithm with start node {start}, start time {start_time}, and max transfers {max_transfers}\")\n",
    "\n",
    "    if start not in graph.adj_list:\n",
    "        logging.error(\"Invalid start node. Valid nodes are:\")\n",
    "        for node in graph.adj_list:\n",
    "            logging.error(node)\n",
    "        return None\n",
    "\n",
    "    distances = {node: float('inf') for node in graph.adj_list}\n",
    "    distances[start] = start_time\n",
    "    priority_queue = [(start_time, start, set(), 0)]\n",
    "    shortest_path_tree = {}\n",
    "    routes_used = {node: set() for node in graph.adj_list}\n",
    "    transfers = {node: float('inf') for node in graph.adj_list}\n",
    "    transfers[start] = 0\n",
    "\n",
    "    logging.debug(f\"Initial distances: {distances}\")\n",
    "    logging.debug(f\"Initial priority queue: {priority_queue}\")\n",
    "    logging.debug(f\"Initial routes used: {routes_used}\")\n",
    "    logging.debug(f\"Initial transfers: {transfers}\")\n",
    "\n",
    "    while priority_queue:\n",
    "        logger.debug(f\"Priority queue: {priority_queue}\")\n",
    "        current_time, current_node, current_routes, current_transfers = heapq.heappop(priority_queue)\n",
    "        logging.debug(f\"Popped node {current_node} with time {current_time}, routes {current_routes}, and transfers {current_transfers}\")\n",
    "\n",
    "        if current_time > distances[current_node]:\n",
    "            logging.debug(f\"Skipping node {current_node} because its time {current_time} is greater than the known shortest time {distances[current_node]}\")\n",
    "            continue\n",
    "\n",
    "        for edge in graph.adj_list[current_node]:\n",
    "            if current_time <= edge.end_time:\n",
    "                wait_time = max(0, edge.start_time - current_time)\n",
    "                arrival_time = current_time + wait_time + edge.weight\n",
    "                logging.debug(f\"Examining edge to node {edge.to} with start time {edge.start_time}, end time {edge.end_time}, and weight {edge.weight}\")\n",
    "                logging.debug(f\"Calculated wait time: {wait_time}, arrival time: {arrival_time}\")\n",
    "\n",
    "                new_transfers = current_transfers\n",
    "                if edge.route not in current_routes:\n",
    "                    new_transfers += 1\n",
    "                    logging.debug(f\"New route {edge.route} requires a transfer, increasing transfers to {new_transfers}\")\n",
    "\n",
    "                if new_transfers > max_transfers:\n",
    "                    logging.debug(f\"Skipping edge to node {edge.to} because it requires {new_transfers} transfers, which exceeds the maximum of {max_transfers}\")\n",
    "                    continue\n",
    "\n",
    "                if arrival_time < distances[edge.to] or (arrival_time == distances[edge.to] and new_transfers < transfers[edge.to]):\n",
    "                    distances[edge.to] = arrival_time\n",
    "                    routes_used[edge.to] = current_routes | {edge.route}\n",
    "                    transfers[edge.to] = new_transfers\n",
    "                    heapq.heappush(priority_queue, (arrival_time, edge.to, current_routes | {edge.route}, new_transfers))\n",
    "                    shortest_path_tree[edge.to] = (current_node, edge.route)\n",
    "                    logging.debug(f\"Updated shortest path to node {edge.to} with time {arrival_time}, routes {routes_used[edge.to]}, and transfers {transfers[edge.to]}\")\n",
    "\n",
    "    logging.debug(f\"Final distances: {distances}\")\n",
    "    logging.debug(f\"Final shortest path tree: {shortest_path_tree}\")\n",
    "    logging.debug(f\"Final routes used: {routes_used}\")\n",
    "    logging.debug(f\"Final transfers: {transfers}\")\n",
    "\n",
    "    return distances, shortest_path_tree, routes_used, transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get node ids from the graph\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m start_time \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m11\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3600\u001b[39m) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m30\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)  \u001b[38;5;66;03m# seconds from midnight\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Apply Dijkstra's algorithm with transfers\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m distances \u001b[38;5;241m=\u001b[39m \u001b[43mdijkstra_with_transfers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_transfers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Display or use results as needed\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShortest distances from start node:\u001b[39m\u001b[38;5;124m\"\u001b[39m, distances)\n",
      "Cell \u001b[0;32mIn[21], line 42\u001b[0m, in \u001b[0;36mdijkstra_with_transfers\u001b[0;34m(graph, start, start_time, max_transfers)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge\u001b[38;5;241m.\u001b[39mroute \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m current_routes:\n\u001b[1;32m     41\u001b[0m     new_transfers \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mlogging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNew route \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43medge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroute\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m requires a transfer, increasing transfers to \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnew_transfers\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_transfers \u001b[38;5;241m>\u001b[39m max_transfers:\n\u001b[1;32m     45\u001b[0m     logging\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping edge to node \u001b[39m\u001b[38;5;132;01m{\u001b[39;00medge\u001b[38;5;241m.\u001b[39mto\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because it requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_transfers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m transfers, which exceeds the maximum of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_transfers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/midpoint/lib/python3.12/logging/__init__.py:2226\u001b[0m, in \u001b[0;36mdebug\u001b[0;34m(msg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(root\u001b[38;5;241m.\u001b[39mhandlers) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2225\u001b[0m     basicConfig()\n\u001b[0;32m-> 2226\u001b[0m \u001b[43mroot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/midpoint/lib/python3.12/logging/__init__.py:1527\u001b[0m, in \u001b[0;36mLogger.debug\u001b[0;34m(self, msg, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;124;03mLog 'msg % args' with severity 'DEBUG'.\u001b[39;00m\n\u001b[1;32m   1520\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;124;03mlogger.debug(\"Houston, we have a %s\", \"thorny problem\", exc_info=True)\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misEnabledFor(DEBUG):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEBUG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/midpoint/lib/python3.12/logging/__init__.py:1684\u001b[0m, in \u001b[0;36mLogger._log\u001b[0;34m(self, level, msg, args, exc_info, extra, stack_info, stacklevel)\u001b[0m\n\u001b[1;32m   1681\u001b[0m         exc_info \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n\u001b[1;32m   1682\u001b[0m record \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmakeRecord(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, level, fn, lno, msg, args,\n\u001b[1;32m   1683\u001b[0m                          exc_info, func, extra, sinfo)\n\u001b[0;32m-> 1684\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/midpoint/lib/python3.12/logging/__init__.py:1700\u001b[0m, in \u001b[0;36mLogger.handle\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_record, LogRecord):\n\u001b[1;32m   1699\u001b[0m     record \u001b[38;5;241m=\u001b[39m maybe_record\n\u001b[0;32m-> 1700\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallHandlers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/midpoint/lib/python3.12/logging/__init__.py:1762\u001b[0m, in \u001b[0;36mLogger.callHandlers\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m   1760\u001b[0m     found \u001b[38;5;241m=\u001b[39m found \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1761\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m record\u001b[38;5;241m.\u001b[39mlevelno \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m hdlr\u001b[38;5;241m.\u001b[39mlevel:\n\u001b[0;32m-> 1762\u001b[0m         \u001b[43mhdlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m c\u001b[38;5;241m.\u001b[39mpropagate:\n\u001b[1;32m   1764\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m    \u001b[38;5;66;03m#break out\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/midpoint/lib/python3.12/logging/__init__.py:1028\u001b[0m, in \u001b[0;36mHandler.handle\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1028\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/midpoint/lib/python3.12/logging/__init__.py:1164\u001b[0m, in \u001b[0;36mStreamHandler.emit\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[38;5;66;03m# issue 35046: merged two stream.writes into one.\u001b[39;00m\n\u001b[1;32m   1163\u001b[0m     stream\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminator)\n\u001b[0;32m-> 1164\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRecursionError\u001b[39;00m:  \u001b[38;5;66;03m# See issue 36272\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/midpoint/lib/python3.12/logging/__init__.py:1144\u001b[0m, in \u001b[0;36mStreamHandler.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1144\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/midpoint/lib/python3.12/site-packages/ipykernel/iostream.py:607\u001b[0m, in \u001b[0;36mOutStream.flush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;66;03m# wait for flush to actually get through, if we can.\u001b[39;00m\n\u001b[1;32m    606\u001b[0m evt \u001b[38;5;241m=\u001b[39m threading\u001b[38;5;241m.\u001b[39mEvent()\n\u001b[0;32m--> 607\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpub_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;66;03m# and give a timeout to avoid\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt\u001b[38;5;241m.\u001b[39mwait(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_timeout):\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;66;03m# write directly to __stderr__ instead of warning because\u001b[39;00m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;66;03m# if this is happening sys.stderr may be the problem.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/midpoint/lib/python3.12/site-packages/ipykernel/iostream.py:267\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    269\u001b[0m     f()\n",
      "File \u001b[0;32m~/miniconda3/envs/midpoint/lib/python3.12/site-packages/zmq/sugar/socket.py:696\u001b[0m, in \u001b[0;36mSocket.send\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    689\u001b[0m         data \u001b[38;5;241m=\u001b[39m zmq\u001b[38;5;241m.\u001b[39mFrame(\n\u001b[1;32m    690\u001b[0m             data,\n\u001b[1;32m    691\u001b[0m             track\u001b[38;5;241m=\u001b[39mtrack,\n\u001b[1;32m    692\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    693\u001b[0m             copy_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_threshold,\n\u001b[1;32m    694\u001b[0m         )\n\u001b[1;32m    695\u001b[0m     data\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m group\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:742\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:789\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mzmq/backend/cython/socket.pyx:250\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/midpoint/lib/python3.12/site-packages/zmq/backend/cython/checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Apply Dijkstra's algorithm\n",
    "start_node = '450011574'\n",
    "start_time = (11 * 3600) + (30* 60)  # seconds from midnight\n",
    "# Apply Dijkstra's algorithm with transfers\n",
    "distances = dijkstra_with_transfers(graph, start_node, start_time, max_transfers= 1)\n",
    "\n",
    "# Display or use results as needed\n",
    "print(\"Shortest distances from start node:\", distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dijkstra_with_transfers(graph, start_node, start_time, max_transfers= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if any of the values in \"distances\" are not infinity\n",
    "distances_dict = distances[0]\n",
    "unique_values = set(distances_dict.values())\n",
    "unique_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_graph(distances, shortest_path_tree, routes_used, start_node):\n",
    "    # Create a new NetworkX graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes to the graph\n",
    "    for node, distance in distances.items():\n",
    "        G.add_node(node, distance=distance)\n",
    "\n",
    "    # Add edges to the graph\n",
    "    for node, (parent, route) in shortest_path_tree.items():\n",
    "        if parent is not None:\n",
    "            G.add_edge(parent, node, route=route)\n",
    "\n",
    "    # Assign colors to nodes based on travel time\n",
    "    node_colors = [distances[node] for node in G.nodes()]\n",
    "\n",
    "    # Draw the graph\n",
    "    pos = nx.spring_layout(G)  # or use other layout algorithms\n",
    "    nx.draw(G, pos, with_labels=True, node_color=node_colors, cmap=plt.cm.plasma)\n",
    "\n",
    "    # Add color bar\n",
    "    sm = plt.cm.ScalarMappable(cmap=plt.cm.plasma, norm=plt.Normalize(vmin=min(node_colors), vmax=max(node_colors)))\n",
    "    sm._A = []  # fake up the array of the scalar mappable\n",
    "    plt.colorbar(sm)\n",
    "\n",
    "    # Show plot\n",
    "    plt.title('Network Visualization with Travel Time')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with distances, shortest_path_tree, routes_used from dijkstra_with_routes\n",
    "visualize_graph(distances, shortest_path_tree, routes_used, start_node = '3200YND56740')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "midpoint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
